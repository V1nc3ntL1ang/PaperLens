import fitz
import logging
import requests
import time
import json
import os
from datetime import datetime
from flask import Flask, request, jsonify, send_file, Response, stream_with_context
from modules.find_references import extract_references
from modules.verify_references import (
    find_best_match,
    get_fallback_reference_verification,
    smart_extract_search_query,
    search_openalex,
)
from modules.find_github_urls import extract_github_urls
from modules.find_candidate_papers import (
    extract_paper_keywords,
    search_candidate_papers_openalex,
    rank_papers_by_similarity,
)
from modules.find_title_and_authors import extract_title_authors_with_ai
from modules.analyze_authors import (
    get_author_from_google_scholar,
    get_author_from_openalex,
    get_author_from_openalex_by_paper,
    generate_team_analysis,
    get_fallback_author_analysis,
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__, static_folder=".", static_url_path="")

# å…è®¸è·¨åŸŸ (æ–¹ä¾¿å¼€å‘æ—¶å‰åç«¯åˆ†ç¦»è°ƒè¯•)
from flask_cors import CORS

CORS(app)


@app.route("/")
def index():
    return send_file("index.html")


@app.route("/api/upload", methods=["POST"])
def upload_pdf():
    if "file" not in request.files:
        return jsonify({"error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400

    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400

    try:
        file_content = file.read()
        doc = fitz.open(stream=file_content, filetype="pdf")

        text = ""
        for page in doc:
            page_text = page.get_text()
            text += page_text + "\n"

        logger.info(f"æå–åˆ°æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")

        page_count = len(doc)

        lines = text.split("\n")
        first_50_lines = "\n".join(lines[:50])

        api_key = request.headers.get("X-API-Key")
        title, authors = extract_title_authors_with_ai(first_50_lines, api_key)

        references = extract_references(text)

        # æå– GitHub é“¾æ¥
        github_urls = extract_github_urls(text)
        logger.info(f"æå–åˆ° GitHub é“¾æ¥: {github_urls}")

        return jsonify(
            {
                "text": text if text else "",
                "page_count": page_count if page_count else 0,
                "references": references if references else [],
                "title": title,
                "authors": authors,
                "github_urls": github_urls,
            }
        )

    except Exception as e:
        logger.error(f"PDFå¤„ç†é”™è¯¯: {str(e)}")
        return jsonify({"error": f"æ— æ³•å¤„ç†PDFæ–‡ä»¶: {str(e)}"}), 500
    finally:
        if "doc" in locals():
            doc.close()

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    messages = data.get('messages', [])
    api_key = request.headers.get('X-API-Key')
    print(f"=== DEBUG: API Key å€¼ ===")
    print(f"API Key æ˜¯å¦å­˜åœ¨: {'X-API-Key' in request.headers}")
    print(f"API Key å€¼: '{api_key}'")
    print(f"API Key é•¿åº¦: {len(api_key) if api_key else 0}")
    print(f"API Key æ˜¯å¦ä¸ºç©º: {not api_key}")
    print(f"API Key æ˜¯å¦ä¸ºNone: {api_key is None}")
    print(f"=== DEBUG ç»“æŸ ===")
    model = data.get('model', 'deepseek-chat')
    api_base = data.get('api_base', 'https://api.deepseek.com/v1')

    if not api_key:
        return jsonify({"error": "æœªæä¾› API Key"}), 401

    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": 3000,
            "temperature": 0.2,
            "stream": False
        }

        response = requests.post(f"{api_base}/chat/completions", headers=headers, json=payload)
        
        if response.status_code != 200:
            return jsonify({"error": f"DeepSeek API Error: {response.text}"}), response.status_code

        return jsonify(response.json())

    except Exception as e:
        return jsonify({"error": str(e)}), 500
    
@app.route('/api/chat/stream', methods=['POST'])
def chat_stream():
    """æµå¼èŠå¤©æ¥å£"""
    data = request.json
    api_key = request.headers.get('X-API-Key')
    
    if not api_key:
        return jsonify({'error': 'ç¼ºå°‘ API Key'}), 401
    
    api_base = data.get('api_base', 'https://api.deepseek.com/v1')
    
    def generate():
        try:
            response = requests.post(
                f"{api_base}/chat/completions",
                headers={
                    'Content-Type': 'application/json',
                    'Authorization': f'Bearer {api_key}'
                },
                json={
                    'model': data.get('model', 'deepseek-chat'),
                    'messages': data.get('messages', []),
                    'stream': True
                },
                stream=True,
                timeout=60
            )
            
            if response.status_code != 200:
                yield f"data: {json.dumps({'error': f'APIé”™è¯¯: {response.status_code}'})}\n\n"
                return
            
            for line in response.iter_lines():
                if line:
                    decoded_line = line.decode('utf-8')
                    yield f"{decoded_line}\n\n"
                    
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        content_type='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'X-Accel-Buffering': 'no'  # ç¦ç”¨ Nginx ç¼“å†²
        }
    )

@app.route("/api/recommend_papers", methods=["POST"])
def recommend_papers():
    """
    æ ¹æ®è®ºæ–‡å†…å®¹æ¨èç›¸å…³è®ºæ–‡ - åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ + OpenAlex
    """
    data = request.get_json()
    paper_text = data.get("text", "") if data else ""
    paper_title = data.get("title", "") if data else ""
    max_results = data.get("max_results", 10) if data else 10

    if not paper_text and not paper_title:
        return jsonify({"error": "è®ºæ–‡å†…å®¹ä¸ºç©º"}), 400

    try:
        # æ„å»ºæŸ¥è¯¢æ–‡æœ¬
        query_text = (
            paper_title + " " + paper_text[:1000] if paper_title else paper_text[:1000]
        )

        logger.info(f"å¼€å§‹è¯­ä¹‰æœç´¢ç›¸å…³è®ºæ–‡ï¼Œæ–‡æœ¬é•¿åº¦: {len(query_text)}")

        # 1. æå–å…³é”®è¯
        keywords = extract_paper_keywords(query_text)
        logger.info(f"æå–å…³é”®è¯: {keywords[:5]}")

        # 2. æœç´¢å€™é€‰è®ºæ–‡
        candidate_papers = search_candidate_papers_openalex(
            query_text, keywords, max_candidates=50
        )

        logger.info(f"å€™é€‰è®ºæ–‡æ•°é‡: {len(candidate_papers)}")  # è°ƒè¯•æ—¥å¿—

        if not candidate_papers:
            return jsonify(
                {
                    "success": True,
                    "error": None,
                    "keywords_used": keywords[:5],
                    "candidates_found": 0,
                    "papers": [],
                    "source": "openalex",
                    "method": "semantic_similarity",
                }
            )

        # 3. ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ’åº
        ranked_papers = rank_papers_by_similarity(
            query_text, candidate_papers, top_k=max_results
        )

        logger.info(f"æ’åºåè®ºæ–‡æ•°é‡: {len(ranked_papers)}")  # è°ƒè¯•æ—¥å¿—

        # 4. æ¸…ç†è¾“å‡ºæ•°æ®
        output_papers = []
        for paper in ranked_papers:
            paper_data = {
                "title": paper.get("title", ""),
                "authors": paper.get("authors", []),
                "year": paper.get("year", ""),
                "citationCount": paper.get("citationCount", 0),
                "venue": paper.get("venue", ""),
                "url": paper.get("url", ""),
                "abstract": (
                    paper.get("abstract", "")[:300] + "..."
                    if len(paper.get("abstract", "")) > 300
                    else paper.get("abstract", "")
                ),
                "similarity": paper.get("similarity_score", 0),
                "relevance": paper.get("total_score", 0),
            }
            output_papers.append(paper_data)

        logger.info(f"è¾“å‡ºè®ºæ–‡æ•°é‡: {len(output_papers)}")  # è°ƒè¯•æ—¥å¿—

        # æ‰“å°å®Œæ•´å“åº”ç”¨äºè°ƒè¯•
        response_data = {
            "success": True,
            "keywords_used": keywords[:5],
            "candidates_found": len(candidate_papers),
            "papers": output_papers,
            "source": "openalex",
            "method": "semantic_similarity",
        }

        logger.info(
            f"è¿”å›å“åº”: success={response_data['success']}, papers_count={len(response_data['papers'])}"
        )

        return jsonify(response_data)

    except Exception as e:
        logger.error(f"è®ºæ–‡æ¨èé”™è¯¯: {str(e)}")
        import traceback

        traceback.print_exc()

        return (
            jsonify(
                {
                    "success": False,
                    "error": f"æ¨èæœåŠ¡å¼‚å¸¸: {str(e)}",
                    "papers": [],
                    "keywords_used": [],
                    "candidates_found": 0,
                }
            ),
            500,
        )


# ä¿®æ”¹ analyze_authors æ¥å£
@app.route("/api/analyze_authors", methods=["POST"])
def analyze_authors():
    """
    ä½¿ç”¨è®ºæ–‡æ ‡é¢˜+ä½œè€…åè”åˆæœç´¢ï¼Œæé«˜ä½œè€…åŒ¹é…å‡†ç¡®æ€§
    """
    data = request.get_json()
    authors = data.get("authors", []) if data else []
    paper_title = data.get("title", "")  # æ–°å¢ï¼šæ¥æ”¶è®ºæ–‡æ ‡é¢˜

    if not authors:
        return jsonify({"error": "ä½œè€…ä¿¡æ¯ä¸ºç©º"}), 400

    logger.info(f"å¼€å§‹åˆ†æä½œè€…ä¿¡æ¯: {authors}")
    logger.info(f"è®ºæ–‡æ ‡é¢˜: {paper_title[:50]}..." if paper_title else "æ— è®ºæ–‡æ ‡é¢˜")

    detailed_authors = []

    for i, author_name in enumerate(authors):
        logger.info(f"è·å–ä½œè€…è¯¦æƒ… {i+1}/{len(authors)}: {author_name}")

        # ä¼˜å…ˆä½¿ç”¨ Google Scholar
        author_details = get_author_from_google_scholar(author_name)

        # å¦‚æœ Google Scholar å¤±è´¥ï¼Œä½¿ç”¨è®ºæ–‡æ ‡é¢˜è”åˆæœç´¢ OpenAlex
        if not author_details.get("searchSuccess"):
            logger.info(f"Google Scholar æœªæ‰¾åˆ°ï¼Œå°è¯•è®ºæ–‡è”åˆæœç´¢: {author_name}")
            author_details = get_author_from_openalex_by_paper(author_name, paper_title)

        detailed_authors.append(author_details)
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«

    return jsonify(
        {
            "success": True,
            "authors_count": len(detailed_authors),
            "authors": detailed_authors,
            "analysis": generate_team_analysis(detailed_authors),
        }
    )


@app.route("/api/update_authors", methods=["POST"])
def update_authors():
    """
    æ‰‹åŠ¨æ›´æ–°ä½œè€…ä¿¡æ¯
    """
    data = request.get_json()
    original_authors = data.get("original_authors", [])
    updated_authors = data.get("updated_authors", [])

    if not original_authors or not updated_authors:
        return jsonify({"error": "ä½œè€…æ•°æ®ä¸èƒ½ä¸ºç©º"}), 400

    try:
        # ä¸ºæ›´æ–°åçš„ä½œè€…è·å–è¯¦ç»†ä¿¡æ¯
        detailed_authors = []
        for i, author in enumerate(updated_authors):
            logger.info(f"è·å–æ›´æ–°ä½œè€…è¯¦æƒ… {i+1}/{len(updated_authors)}: {author}")
            author_details = get_author_from_google_scholar(author)

            # å¦‚æœ Google Scholar å¤±è´¥ï¼Œå°è¯• OpenAlex
            if not author_details.get("searchSuccess"):
                logger.info(f"Google Scholar æœªæ‰¾åˆ°ï¼Œå°è¯• OpenAlex: {author}")
            author_details = get_author_from_openalex(author)
            if author_details:
                detailed_authors.append(author_details)
            time.sleep(0.5)

        return jsonify(
            {
                "success": True,
                "authors_count": len(detailed_authors),
                "authors": detailed_authors,
                "analysis": generate_team_analysis(detailed_authors),
                "original_authors": original_authors,
                "updated_authors": updated_authors,
            }
        )

    except Exception as e:
        logger.error(f"ä½œè€…æ›´æ–°é”™è¯¯: {str(e)}")
        return (
            jsonify(
                {
                    "error": f"ä½œè€…æ›´æ–°å¤±è´¥: {str(e)}",
                    "fallback_data": get_fallback_author_analysis(),
                }
            ),
            200,
        )


@app.route("/api/get_citations", methods=["POST"])
def get_citations():
    """
    ä½¿ç”¨ OpenAlex API è·å–å¼•ç”¨è®ºæ–‡ï¼ˆå®Œå…¨å…è´¹ï¼Œæ— éœ€ Keyï¼‰
    """
    data = request.get_json()
    paper_title = data.get("title", "")

    if not paper_title:
        return jsonify({"error": "è®ºæ–‡æ ‡é¢˜ä¸èƒ½ä¸ºç©º"}), 400

    logger.info(f"æœç´¢å¼•ç”¨è®ºæ–‡ï¼Œæ ‡é¢˜: {paper_title}")

    try:
        headers = {"User-Agent": "PaperLens/1.0 (mailto:contact@example.com)"}

        # 1. æœç´¢è®ºæ–‡
        search_url = "https://api.openalex.org/works"
        search_params = {"search": paper_title, "per_page": 1}

        search_response = requests.get(
            search_url, params=search_params, headers=headers, timeout=15
        )

        if search_response.status_code != 200:
            raise Exception(f"æœç´¢å¤±è´¥: {search_response.status_code}")

        search_data = search_response.json()
        results = search_data.get("results", [])

        if not results:
            return jsonify(
                {
                    "success": False,
                    "error": "æœªæ‰¾åˆ°è¯¥è®ºæ–‡",
                    "fallback_used": True,
                    "citations": (),
                }
            )

        paper = results[0]
        paper_id = paper.get("id", "").replace("https://openalex.org/", "")

        # 2. è·å–å¼•ç”¨è¯¥è®ºæ–‡çš„æ–‡çŒ®
        citations_url = "https://api.openalex.org/works"
        citations_params = {
            "filter": f"cites:{paper_id}",
            "per_page": 20,
            "sort": "cited_by_count:desc",
        }

        citations_response = requests.get(
            citations_url, params=citations_params, headers=headers, timeout=15
        )

        if citations_response.status_code != 200:
            raise Exception(f"è·å–å¼•ç”¨å¤±è´¥: {citations_response.status_code}")

        citations_data = citations_response.json()
        citing_works = citations_data.get("results", [])

        # 3. æ ¼å¼åŒ–ç»“æœ
        formatted_citations = []
        for work in citing_works:
            # æå–ä½œè€…ï¼ˆæœ€å¤š3ä¸ªï¼‰
            authors = []
            for authorship in work.get("authorships", [])[:3]:
                author = authorship.get("author", {})
                if author.get("display_name"):
                    authors.append({"name": author["display_name"]})

            # æå–æ‘˜è¦
            abstract = ""
            if work.get("abstract_inverted_index"):
                # OpenAlex çš„æ‘˜è¦æ˜¯å€’æ’ç´¢å¼•æ ¼å¼ï¼Œéœ€è¦è¿˜åŸ
                try:
                    inverted = work["abstract_inverted_index"]
                    word_positions = []
                    for word, positions in inverted.items():
                        for pos in positions:
                            word_positions.append((pos, word))
                    word_positions.sort()
                    abstract = " ".join([w for _, w in word_positions])[:300] + "..."
                except:
                    abstract = ""

            # æå–æœŸåˆŠ/ä¼šè®®åç§°
            venue = ""
            primary_location = work.get("primary_location", {})
            if primary_location:
                source = primary_location.get("source", {})
                if source:
                    venue = source.get("display_name", "")

            # æå– URL
            url = work.get("doi", "")
            if url and not url.startswith("http"):
                url = f"https://doi.org/{url}"
            if not url:
                url = work.get("id", "")

            formatted_citations.append(
                {
                    "title": work.get("title", "æœªçŸ¥æ ‡é¢˜"),
                    "authors": authors,
                    "year": work.get("publication_year"),
                    "venue": venue,
                    "url": url,
                    "citationCount": work.get("cited_by_count", 0),
                    "abstract": abstract,
                }
            )

        return jsonify(
            {
                "success": True,
                "source": "OpenAlex",
                "original_paper": {
                    "title": paper.get("title", paper_title),
                    "citationCount": paper.get("cited_by_count", 0),
                    "year": paper.get("publication_year"),
                    "doi": paper.get("doi", ""),
                },
                "citations_count": len(formatted_citations),
                "citations": formatted_citations,
            }
        )

    except Exception as e:
        logger.error(f"OpenAlex API é”™è¯¯: {e}")
        return jsonify(
            {
                "success": False,
                "error": str(e),
                "fallback_used": True,
                "original_paper": {"title": paper_title, "citationCount": 0},
                "citations_count": len(get_fallback_citations()),
                "citations": get_fallback_citations(),
            }
        )


def get_fallback_citations():
    """
    è¿”å›ç¤ºä¾‹å¼•ç”¨æ•°æ®
    """
    return [
        {
            "title": "æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æœ€æ–°è¿›å±•",
            "authors": [{"name": "å¼ ä¼Ÿ"}, {"name": "æé™"}],
            "year": 2023,
            "venue": "äººå·¥æ™ºèƒ½å­¦æŠ¥",
            "citationCount": 45,
            "abstract": "æœ¬æ–‡ç»¼è¿°äº†æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„æœ€æ–°ç ”ç©¶æˆæœå’Œåº”ç”¨å‰æ™¯...",
            "url": "https://example.com/paper1",
        },
        {
            "title": "åŸºäºTransformerçš„æ–‡æœ¬è¡¨ç¤ºå­¦ä¹ ç ”ç©¶",
            "authors": [{"name": "ç‹æ˜"}, {"name": "èµµé›ª"}],
            "year": 2022,
            "venue": "è®¡ç®—æœºç ”ç©¶",
            "citationCount": 32,
            "abstract": "æ¢è®¨äº†Transformeræ¶æ„åœ¨æ–‡æœ¬è¡¨ç¤ºå­¦ä¹ ä¸­çš„åº”ç”¨å’Œä¼˜åŒ–æ–¹æ³•...",
            "url": "https://example.com/paper2",
        },
        {
            "title": "é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ•ˆç‡ä¼˜åŒ–ç­–ç•¥",
            "authors": [{"name": "åˆ˜å¼º"}, {"name": "é™ˆäº‘"}],
            "year": 2023,
            "venue": "è½¯ä»¶å­¦æŠ¥",
            "citationCount": 28,
            "abstract": "ç ”ç©¶äº†å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ•ˆç‡ä¼˜åŒ–å’Œéƒ¨ç½²ç­–ç•¥...",
            "url": "https://example.com/paper3",
        },
    ]


@app.route("/api/verify_reference", methods=["POST"])
def verify_reference():
    """
    æ™ºèƒ½å¼•ç”¨éªŒè¯ - ä½¿ç”¨AIæå–æœç´¢å…³é”®è¯
    """
    data = request.json
    ref_text = data.get("reference", "")

    if not ref_text:
        return jsonify({"error": "å¼•ç”¨æ–‡æœ¬ä¸ºç©º"}), 400

    try:
        logger.info(f"å¼€å§‹æ™ºèƒ½éªŒè¯å¼•ç”¨: {ref_text[:100]}...")

        # ä½¿ç”¨AIæå–æœç´¢æŸ¥è¯¢
        search_query = smart_extract_search_query(
            ref_text,
            request.headers.get("X-API-Key"),  # ä»headerè·å–API Key
            data.get("api_base", "https://api.deepseek.com/v1"),
        )

        logger.info(f"AIæå–çš„æœç´¢è¯: {search_query}")

        # æœç´¢OpenAlex
        papers = search_openalex(search_query, max_results=3)

        if papers:
            # æ‰¾åˆ°æœ€ä½³åŒ¹é…
            best_match = find_best_match(ref_text, papers)

            if best_match["score"] > 0.3:  # åŒ¹é…åº¦é˜ˆå€¼
                return jsonify(
                    {
                        "found": True,
                        "match_score": best_match["score"],
                        "data": best_match["paper"],
                        "search_query_used": search_query,
                        "ai_extraction_used": True,
                        "candidates": len(papers),
                    }
                )
            else:
                return jsonify(
                    {
                        "found": False,
                        "match_score": best_match["score"],
                        "message": f"æ‰¾åˆ°ç›¸å…³è®ºæ–‡ä½†åŒ¹é…åº¦è¾ƒä½ ({(best_match['score']):.2f})",
                        "best_candidate": {
                            "title": best_match["paper"].get("title"),
                            "year": best_match["paper"].get("year"),
                            "authors": [
                                a.get("name")
                                for a in best_match["paper"].get("authors", [])
                            ][:3],
                        },
                        "search_query_used": search_query,
                        "ai_extraction_used": True,
                    }
                )
        else:
            return jsonify(
                {
                    "found": False,
                    "message": "æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡",
                    "search_query_used": search_query,
                    "ai_extraction_used": True,
                }
            )

    except Exception as e:
        logger.error(f"æ™ºèƒ½å¼•ç”¨éªŒè¯é”™è¯¯: {str(e)}")
        # å‡ºé”™æ—¶ä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
        return (
            jsonify(
                {
                    "error": f"éªŒè¯æœåŠ¡å¼‚å¸¸: {str(e)}",
                    "fallback_data": get_fallback_reference_verification(ref_text),
                }
            ),
            200,
        )


# ç¬”è®°å­˜å‚¨åŠŸèƒ½
NOTES_DIR = "user_notes"  # ç¬”è®°å­˜å‚¨ç›®å½•
os.makedirs(NOTES_DIR, exist_ok=True)


def get_note_filename(pdf_hash, user_id="default"):
    """ç”Ÿæˆç¬”è®°æ–‡ä»¶å"""
    return f"{NOTES_DIR}/{user_id}_{pdf_hash}.json"


def calculate_pdf_hash(file_content):
    """è®¡ç®—PDFæ–‡ä»¶çš„å“ˆå¸Œå€¼ä½œä¸ºå”¯ä¸€æ ‡è¯†"""
    import hashlib

    return hashlib.md5(file_content).hexdigest()


@app.route("/api/save_note", methods=["POST"])
def save_note():
    """
    ä¿å­˜è®ºæ–‡ç¬”è®°
    """
    try:
        data = request.get_json()
        pdf_content = data.get("pdf_content", "")
        notes = data.get("notes", {})
        user_id = data.get("user_id", "default")  # å¯ä»¥æ‰©å±•ä¸ºå¤šç”¨æˆ·

        if not pdf_content:
            return jsonify({"error": "PDFå†…å®¹ä¸èƒ½ä¸ºç©º"}), 400

        # è®¡ç®—PDFå“ˆå¸Œä½œä¸ºå”¯ä¸€æ ‡è¯†
        pdf_hash = calculate_pdf_hash(pdf_content.encode("utf-8"))

        note_data = {
            "pdf_hash": pdf_hash,
            "notes": notes,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "page_count": len(notes),  # æœ‰ç¬”è®°çš„é¡µæ•°
        }

        # ä¿å­˜åˆ°æ–‡ä»¶
        filename = get_note_filename(pdf_hash, user_id)
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(note_data, f, ensure_ascii=False, indent=2)

        return jsonify(
            {
                "success": True,
                "message": "ç¬”è®°ä¿å­˜æˆåŠŸ",
                "pdf_hash": pdf_hash,
                "saved_pages": len(notes),
            }
        )

    except Exception as e:
        logger.error(f"ä¿å­˜ç¬”è®°é”™è¯¯: {str(e)}")
        return jsonify({"error": f"ä¿å­˜å¤±è´¥: {str(e)}"}), 500


@app.route("/api/load_note", methods=["POST"])
def load_note():
    """
    åŠ è½½è®ºæ–‡ç¬”è®°
    """
    try:
        data = request.get_json()
        pdf_content = data.get("pdf_content", "")
        user_id = data.get("user_id", "default")

        if not pdf_content:
            return jsonify({"error": "PDFå†…å®¹ä¸èƒ½ä¸ºç©º"}), 400

        pdf_hash = calculate_pdf_hash(pdf_content.encode("utf-8"))
        filename = get_note_filename(pdf_hash, user_id)

        if os.path.exists(filename):
            with open(filename, "r", encoding="utf-8") as f:
                note_data = json.load(f)
            return jsonify(
                {
                    "success": True,
                    "notes": note_data.get("notes", {}),
                    "created_at": note_data.get("created_at"),
                    "updated_at": note_data.get("updated_at"),
                }
            )
        else:
            return jsonify({"success": True, "notes": {}, "message": "æœªæ‰¾åˆ°ç°æœ‰ç¬”è®°"})

    except Exception as e:
        logger.error(f"åŠ è½½ç¬”è®°é”™è¯¯: {str(e)}")
        return jsonify({"error": f"åŠ è½½å¤±è´¥: {str(e)}"}), 500


@app.route("/api/export_notes", methods=["POST"])
def export_notes():
    """
    å¯¼å‡ºç¬”è®°ä¸º Markdown æ ¼å¼
    """
    try:
        data = request.get_json()
        notes = data.get("notes", {})
        paper_title = data.get("paper_title", "æœªå‘½åè®ºæ–‡")

        # æ„å»º Markdown å†…å®¹
        markdown = f"# ğŸ“š è®ºæ–‡ç¬”è®°ï¼š{paper_title}\n\n"
        markdown += f"**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        markdown += "---\n\n"

        # å…¨å±€ç¬”è®°
        global_note = notes.get("global", "")
        if global_note:
            markdown += "## ğŸ“ å…¨å±€ç¬”è®°\n\n"
            markdown += f"{global_note}\n\n"
            markdown += "---\n\n"

        # é¡µé¢ç¬”è®°
        pages = notes.get("pages", {})
        if pages:
            markdown += "## ğŸ“„ é¡µé¢ç¬”è®°\n\n"

            # æŒ‰é¡µç æ’åº
            sorted_pages = sorted(pages.items(), key=lambda x: int(x[0]))

            for page_num, content in sorted_pages:
                if content:  # åªå¯¼å‡ºæœ‰å†…å®¹çš„é¡µé¢
                    markdown += f"### ç¬¬ {page_num} é¡µ\n\n"
                    markdown += f"{content}\n\n"

            markdown += "---\n\n"

        # ç»Ÿè®¡ä¿¡æ¯
        page_count = len([p for p in pages.values() if p])
        markdown += "## ğŸ“Š ç»Ÿè®¡\n\n"
        markdown += f"- å…¨å±€ç¬”è®°å­—æ•°: {len(global_note)} å­—\n"
        markdown += f"- é¡µé¢ç¬”è®°æ•°é‡: {page_count} é¡µ\n"
        markdown += f"- æ€»å­—æ•°: {len(global_note) + sum(len(p) for p in pages.values() if p)} å­—\n"

        return jsonify(
            {
                "success": True,
                "markdown": markdown,
                "filename": f"è®ºæ–‡ç¬”è®°_{paper_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            }
        )

    except Exception as e:
        logger.error(f"å¯¼å‡ºç¬”è®°é”™è¯¯: {str(e)}")
        return jsonify({"error": f"å¯¼å‡ºå¤±è´¥: {str(e)}"}), 500


if __name__ == "__main__":
    print("å¯åŠ¨ PaperLens åç«¯æœåŠ¡...")
    print("è¯·è®¿é—®: http://localhost:5000")
    app.run(debug=True, port=5000)
